{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e872ad83",
   "metadata": {},
   "source": [
    "## Prepare Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3db42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9251c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/20 23:08:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\\\n",
    "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", \"true\")\\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"1\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd03c27",
   "metadata": {},
   "source": [
    "## Songs Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21216cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "songs_df = spark.read.load(\"./songs_dataset/train_triplets.txt\",\n",
    "                     format=\"csv\", sep=\"\\t\", inferSchema=\"true\", \n",
    "                     header=\"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2712e87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6327d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = songs_df.withColumnRenamed(\"_c0\", \"user\")\\\n",
    "                   .withColumnRenamed(\"_c1\", \"song\")\\\n",
    "                   .withColumnRenamed(\"_c2\", \"play_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cdc6042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user: string (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- play_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songs_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c9d86",
   "metadata": {},
   "source": [
    "## Saving to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53dd5c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/20 23:08:31 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "21/11/20 23:08:46 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "21/11/20 23:08:57 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "songs_df.write.parquet(\"songs.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c93402",
   "metadata": {},
   "source": [
    "## Trivial Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d116ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df.createOrReplaceTempView(\"songs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f05df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_count_10 = spark.sql(\"select song from songs where play_count > 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c0eabeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              song|\n",
      "+------------------+\n",
      "|SOQTRKE12A6701C596|\n",
      "|SOVVNSS12A58291F72|\n",
      "|SOEPZQS12A8C1436C7|\n",
      "|SOWPAXV12A67ADA046|\n",
      "|SOXGQEM12AB0181D35|\n",
      "|SOWUVFQ12AB018740E|\n",
      "|SOVFDZD12A6D4F8EAE|\n",
      "|SOADQPP12A67020C82|\n",
      "|SOBONKR12A58A7A7E0|\n",
      "|SOPSOHT12A67AE0235|\n",
      "|SOTTNZU12A6D4FA237|\n",
      "|SOWNNPR12A6D4FB51B|\n",
      "|SOADGFH12A8C143D89|\n",
      "|SOAFOBL12AF72A25BA|\n",
      "|SOAMPRJ12A8AE45F38|\n",
      "|SOAUXEN12A81C23960|\n",
      "|SOCFPSZ12A6D4FCA89|\n",
      "|SOCJCVE12A8C13CDDB|\n",
      "|SODTJFU12B0B80C9BE|\n",
      "|SOFFGTH12A67AE0925|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "play_count_10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1bb6644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2043582"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_count_10.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497d5195",
   "metadata": {},
   "source": [
    "## Yelp Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd571d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/20 23:09:21 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "business = spark.read.json(\"./yelp-dataset/yelp_academic_dataset_business.json\")\n",
    "reviews = spark.read.json(\"./yelp-dataset/yelp_academic_dataset_review.json\")\n",
    "users = spark.read.json(\"./yelp-dataset/yelp_academic_dataset_user.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b52bbb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "business.createOrReplaceTempView(\"business\")\n",
    "reviews.createOrReplaceTempView(\"reviews\")\n",
    "users.createOrReplaceTempView(\"users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b70cd77",
   "metadata": {},
   "source": [
    "### Inspecting Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c643c65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- address: string (nullable = true)\n",
      " |-- attributes: struct (nullable = true)\n",
      " |    |-- AcceptsInsurance: string (nullable = true)\n",
      " |    |-- AgesAllowed: string (nullable = true)\n",
      " |    |-- Alcohol: string (nullable = true)\n",
      " |    |-- Ambience: string (nullable = true)\n",
      " |    |-- BYOB: string (nullable = true)\n",
      " |    |-- BYOBCorkage: string (nullable = true)\n",
      " |    |-- BestNights: string (nullable = true)\n",
      " |    |-- BikeParking: string (nullable = true)\n",
      " |    |-- BusinessAcceptsBitcoin: string (nullable = true)\n",
      " |    |-- BusinessAcceptsCreditCards: string (nullable = true)\n",
      " |    |-- BusinessParking: string (nullable = true)\n",
      " |    |-- ByAppointmentOnly: string (nullable = true)\n",
      " |    |-- Caters: string (nullable = true)\n",
      " |    |-- CoatCheck: string (nullable = true)\n",
      " |    |-- Corkage: string (nullable = true)\n",
      " |    |-- DietaryRestrictions: string (nullable = true)\n",
      " |    |-- DogsAllowed: string (nullable = true)\n",
      " |    |-- DriveThru: string (nullable = true)\n",
      " |    |-- GoodForDancing: string (nullable = true)\n",
      " |    |-- GoodForKids: string (nullable = true)\n",
      " |    |-- GoodForMeal: string (nullable = true)\n",
      " |    |-- HairSpecializesIn: string (nullable = true)\n",
      " |    |-- HappyHour: string (nullable = true)\n",
      " |    |-- HasTV: string (nullable = true)\n",
      " |    |-- Music: string (nullable = true)\n",
      " |    |-- NoiseLevel: string (nullable = true)\n",
      " |    |-- Open24Hours: string (nullable = true)\n",
      " |    |-- OutdoorSeating: string (nullable = true)\n",
      " |    |-- RestaurantsAttire: string (nullable = true)\n",
      " |    |-- RestaurantsCounterService: string (nullable = true)\n",
      " |    |-- RestaurantsDelivery: string (nullable = true)\n",
      " |    |-- RestaurantsGoodForGroups: string (nullable = true)\n",
      " |    |-- RestaurantsPriceRange2: string (nullable = true)\n",
      " |    |-- RestaurantsReservations: string (nullable = true)\n",
      " |    |-- RestaurantsTableService: string (nullable = true)\n",
      " |    |-- RestaurantsTakeOut: string (nullable = true)\n",
      " |    |-- Smoking: string (nullable = true)\n",
      " |    |-- WheelchairAccessible: string (nullable = true)\n",
      " |    |-- WiFi: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- hours: struct (nullable = true)\n",
      " |    |-- Friday: string (nullable = true)\n",
      " |    |-- Monday: string (nullable = true)\n",
      " |    |-- Saturday: string (nullable = true)\n",
      " |    |-- Sunday: string (nullable = true)\n",
      " |    |-- Thursday: string (nullable = true)\n",
      " |    |-- Tuesday: string (nullable = true)\n",
      " |    |-- Wednesday: string (nullable = true)\n",
      " |-- is_open: long (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8681e418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fedece4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- average_stars: double (nullable = true)\n",
      " |-- compliment_cool: long (nullable = true)\n",
      " |-- compliment_cute: long (nullable = true)\n",
      " |-- compliment_funny: long (nullable = true)\n",
      " |-- compliment_hot: long (nullable = true)\n",
      " |-- compliment_list: long (nullable = true)\n",
      " |-- compliment_more: long (nullable = true)\n",
      " |-- compliment_note: long (nullable = true)\n",
      " |-- compliment_photos: long (nullable = true)\n",
      " |-- compliment_plain: long (nullable = true)\n",
      " |-- compliment_profile: long (nullable = true)\n",
      " |-- compliment_writer: long (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- elite: string (nullable = true)\n",
      " |-- fans: long (nullable = true)\n",
      " |-- friends: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- yelping_since: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b353a962",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c81ce95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|state|count|\n",
      "+-----+-----+\n",
      "|   AZ|56686|\n",
      "|   NV|36312|\n",
      "|   ON|33412|\n",
      "|   NC|14720|\n",
      "|   OH|14697|\n",
      "|   PA|11216|\n",
      "|   QC| 9219|\n",
      "|   AB| 8012|\n",
      "|   WI| 5154|\n",
      "|   IL| 1932|\n",
      "|   SC| 1162|\n",
      "|   NY|   22|\n",
      "|   CA|   19|\n",
      "|   TX|    6|\n",
      "|   FL|    4|\n",
      "|  XGM|    4|\n",
      "|   AL|    3|\n",
      "|   WA|    3|\n",
      "|   CT|    3|\n",
      "|   VA|    2|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT state, count(state) \n",
    "AS count \n",
    "FROM business \n",
    "GROUP BY state \n",
    "ORDER BY count(state) DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6659b49f",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "268b8fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT category)|\n",
      "+------------------------+\n",
      "|                    2468|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13:===========================================>              (6 + 2) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT count(distinct(*)) FROM (\n",
    "    SELECT explode(split(categories, \\\",\\s*\\\")) \n",
    "    AS category \n",
    "    FROM business\n",
    ")\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cfb18f",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c691808c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+\n",
      "|         category|count(category)|\n",
      "+-----------------+---------------+\n",
      "|      Restaurants|           2815|\n",
      "|         Shopping|           2416|\n",
      "|    Home Services|           2302|\n",
      "|             Food|           1672|\n",
      "| Health & Medical|           1577|\n",
      "|   Local Services|           1444|\n",
      "|      Restaurants|           1184|\n",
      "|       Automotive|           1164|\n",
      "|    Beauty & Spas|           1115|\n",
      "|    Home Services|            843|\n",
      "+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT category, count(category) FROM \n",
    "    (\n",
    "        SELECT explode(split(categories, \\\",\\s*\\\")) \n",
    "        AS category \n",
    "        FROM business WHERE city=\\\"Phoenix\\\"\n",
    "    )\n",
    "GROUP BY category \n",
    "ORDER BY count(category) DESC LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0006f",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "693a7f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=====================================================>  (18 + 1) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|friend_count|\n",
      "+------------+\n",
      "|        4166|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "SELECT count(*) \n",
    "AS friend_count \n",
    "FROM users \n",
    "WHERE size(split(friends, \\\",\\s*\\\")) > 1000\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cfaf5d",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69011fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|         business_id|            rating|            rating|\n",
      "+--------------------+------------------+------------------+\n",
      "|VHsNB3pdGVcRgs6C3...|3.3461538461538463|2.7857142857142856|\n",
      "|avljb14OB8UkFTHVo...|               4.0|               3.0|\n",
      "|dk1MV0MP32Xq-iBxz...|2.1379310344827585|2.0392156862745097|\n",
      "|GGxnlrfvWy7LFvjN5...| 4.214285714285714| 4.097560975609756|\n",
      "|GJ2TXArxyuF8f79Wb...|               5.0|               4.8|\n",
      "|vnNRBq0zVIH-k1BA9...|               4.0|               3.5|\n",
      "|M4D-cZ9_9Bw-gMi0d...|               5.0| 4.923076923076923|\n",
      "|RMjCnixEY5i12Ciqn...|3.3333333333333335|               2.7|\n",
      "|jfdUtdkXogP2kjK5K...|              3.25|               3.0|\n",
      "|XgX0JhqleOnH-ezSe...|               4.0|2.3333333333333335|\n",
      "|yMKisHBS_Ia8Dr27A...|               3.5|               2.6|\n",
      "|C5H-eZfnxBkYN40xc...| 4.333333333333333| 2.111111111111111|\n",
      "|9HG09ZNqzrEUz-ipS...|               2.6|               2.0|\n",
      "|yNp0G1G4-iYNnuC7V...|              3.75|2.6666666666666665|\n",
      "|N1Gdq44mY5c7NEazh...| 4.333333333333333|               3.5|\n",
      "|B4t9umS5dCUrfTfrd...|               5.0|               4.5|\n",
      "|xYL8AxbYQFkCT1yGu...|2.3333333333333335|              2.25|\n",
      "|Es-MfCr79uHI-CSrz...| 3.142857142857143|1.8823529411764706|\n",
      "|9CkeCB1VzP2VZ221V...|               4.0|               3.0|\n",
      "|0X620JR8m7BSPt5xa...|               4.6|               4.0|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "WITH business_ratings AS (\n",
    "    SELECT business_id, year(to_date(date)) AS year, avg(stars) AS rating \n",
    "    FROM reviews GROUP BY business_id, year(to_date(date))\n",
    "),\n",
    "business_2014 AS (\n",
    "    SELECT business_id, rating \n",
    "    FROM business_ratings\n",
    "    WHERE year=2014\n",
    "),\n",
    "business_2017 AS (\n",
    "    SELECT business_id, rating \n",
    "    FROM business_ratings WHERE year=2017\n",
    ")\n",
    "SELECT business_2014.business_id, business_2014.rating, business_2017.rating \n",
    "FROM business_2014 \n",
    "INNER JOIN business_2017 \n",
    "ON business_2014.business_id=business_2017.business_id \n",
    "WHERE business_2017.rating < business_2014.rating \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e3d6b",
   "metadata": {},
   "source": [
    "### HW: Query 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ccc0a",
   "metadata": {},
   "source": [
    "The goal is to get the list of people whose friends last time wrote a review for a chinese restaurant.\n",
    "\n",
    "**The outline**: \\\n",
    "You will need to look at `reviews`, group by `user_id`. You are interested only in the last review that a person wrote. The `date` is stored as a string. Convert it to date format using `to_date`. Find the most recent date for a user using aggregation function `max`. Note that a person can write several reviews on the same day. Treat all of them as most recent. If the review was written for a Chinese restaurant, we should find who has this person in their friend list. The list of `friends` in stored in table `users`. The field `friends` is also stored as string, and you should split it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bef2cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             user_id|\n",
      "+--------------------+\n",
      "|AfuFQIWXz50GE4TZ5...|\n",
      "| ivm6bLIy2kGx-tuj...|\n",
      "| L6wUxmUErIR7FJij...|\n",
      "| kNuQsqcqTOy_5lQ_...|\n",
      "| Xxvz5g67eaCr3emn...|\n",
      "| hk8o_YrQY31c9Sm5...|\n",
      "| SeWZYXztsqDvuMgF...|\n",
      "| HMfEpwxTmlxxw0Zo...|\n",
      "| leGhN-KSfIdIho2I...|\n",
      "| Z_ZLQ9mj03sVZ9G7...|\n",
      "| mzwmFGcLqaR0IHqd...|\n",
      "| OSG63vuflUELLIJT...|\n",
      "| 7qyzGvU8NN3psfQi...|\n",
      "| DKsGJpKOjRWSeWbs...|\n",
      "| ugDuOj80BPxXsPSP...|\n",
      "| _hm8U41mh5uhd4t6...|\n",
      "| INbtAUNKtZSXr20_...|\n",
      "| x3Z6mJPgtnF5ni1e...|\n",
      "|0MUXAy_zbclghJe6F...|\n",
      "| fb9sMy7ixsOQyW4B...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "WITH \n",
    "last_reviews AS (\n",
    "    SELECT user_id, business_id\n",
    "    FROM reviews\n",
    "    WHERE EXISTS (\n",
    "        SELECT user_id, max(to_date(date)) AS last \n",
    "        FROM reviews\n",
    "        GROUP BY user_id\n",
    "    )\n",
    "),\n",
    "user_friends AS (\n",
    "    SELECT user_id, explode(split(friends, \\\",\\s*\\\")) \n",
    "    AS friend\n",
    "    FROM users\n",
    "),\n",
    "business_categories AS (\n",
    "    SELECT business_id, explode(split(categories, \\\",\\s*\\\")) \n",
    "    AS category\n",
    "    FROM business\n",
    "),\n",
    "chinese_businesses AS (\n",
    "    SELECT *\n",
    "    FROM business_categories\n",
    "    WHERE category='Chinese'\n",
    ")\n",
    "SELECT friend as user_id\n",
    "FROM last_reviews\n",
    "LEFT JOIN user_friends ON last_reviews.user_id=user_friends.user_id \n",
    "INNER JOIN chinese_businesses ON last_reviews.business_id=chinese_businesses.business_id\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7513449",
   "metadata": {},
   "source": [
    "To determine number of rows returned, we can call `count` of a dataframe. However, for me it yields memory error as well as count in SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8e67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
